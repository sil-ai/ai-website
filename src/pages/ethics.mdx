---
title: Ethics Statement
---

# SIL's AI Ethics Statement

The rapid advancement of Artificial Intelligence (AI) and Natural Language Processing (NLP) 
technologies present opportunities for language communities, NGOs, governments, private sector partners 
and technologists to expand possibilities for every language community.
However, these opportunities also come with the risk of compromising values and organizational mission. 
To guard against the inappropriate use of technology and the harm such efforts could produce, 
SIL has put together an ethical framework relevant to the context of development and usage of AI and NLP. 
This framework is the first step in SIL’s commitment to educate and resource its staff, partners and vendors.
It will also form the foundation of SIL’s ongoing efforts to assess ethical behavior and identify areas 
that require further reflection. Adhering to these ethical principles is intended to prevent the most easily 
preventable misuse; but cannot be considered exhaustive and current to every threat.

<b>Encourage People to Flourish</b>

Every AI and NLP activity should be undertaken with a clear, expressed benefit 
to a local language community or indirectly in fulfilling our core mission. 
This includes SIL staff and volunteers fulfilling the organization’s mission in their work. 
Informed by our relationships with local language communities, we will advocate 
for including their perspectives in discussions about AI. 
We will not engage in morally neutral “because we can” activities, 
but will seek to benefit users of all languages by being:
<ul>
    <li>
        <b>Just: </b>
        doing what is right and fair, addressing AI inequities across languages 
        and working to mitigate or overcome unfair algorithmic and social biases;
    </li>
    <li>
        <b>Kind: </b>
        working to make technology that supports flourishing by considering 
        the needs of marginalized language communities. 
        This includes recognizing the value of and taking into account 
        those who may be negatively affected by these new technologies; and
    </li>
    <li>
        <b>Humble: </b>
        being transparent and honest about our actions and the limits of the technology.
    </li>
</ul>

Finally, we affirm the unique and irreplaceable role of human contribution 
and will avoid personifying AI tools and services as if they were human. 
We will thoughtfully consider people’s contribution to SIL’s mission and identify 
how AI can support them in accomplishing it. 

<b>Privacy and Security</b>

Respecting the dignity of all people, we will collect sensitive private data for AI use 
only with expressed and well-informed consent. We will minimize the use of this data, 
allowing individuals to maintain agency over their sensitive private data 
when the use of such data is necessary. As we collect this data, 
we will make clear in advance the intended use of the data, and any plans for retention, 
processing, use, sharing, or selling of that data. 
This consent information should accompany the data throughout its life-cycle. 
Regarding general data collected in the past or present for which we have legal ownership, 
if questions arise we will provide opportunity for language communities to comment on 
and discuss its permissible use. When we acquire data from others, 
we will request assurances of ethical consent before acquiring or deploying sensitive private data. 
When acquiring general data with clear ownership, we will request assurances of ownership and rights 
to license the data in question for AI use. Should we fail to bring such data into full compliance, 
we will be proactive about preventing harm from our use of the data. 
If data is collected from or about children, additional consent from the child’s parent or legal guardian 
will be required. AI models trained on private data will be secured against inadvertent disclosure. 
Private data, models, and critical information about personnel 
and activities will be securely stored and handled. 

<b>Accountability</b>

No AI system will operate without a designated person responsible for the AI system, 
generally the AI project lead or their direct supervisor. 
In addition, a different person(s) should be responsible for monitoring the effects 
of the AI usage on the people and processes in the areas where it is used. 
Each of these persons should be empowered to pause, restrict, or terminate AI usage 
in their area of responsibility, if necessary. 

We will maintain respect for the authorities in areas where we serve by remaining aware of the relevant laws. 
Consideration will be given to these laws in determining how or if we will provide AI support and services. 
In cases where an existing service will be decommissioned, 
we will seek to give notice with adequate time for adjustments to be made. 
Should an AI system be implemented to perform essential work for a team or organization, 
they should maintain adequate fallback technical and human systems 
(keeping a human-in-the-loop whenever possible). In our published work and code, 
we will give credit with appropriate citations or references to the work of others we have used. 
We will maintain a system to address grievances (see contact section below).

<b>Harmful/Inappropriate Content</b>

In line with existing SIL policies, AI systems and users of AI systems shall not knowingly 
create material or take actions  that contain or provoke: hate, harassment, abuse, violence, 
self-harm, sexually transgressive content, political content, spam, deception, or malware.

In addition to those categories which are always harmful and should be strictly forbidden, 
additional categories represent risks that should be closely monitored to ensure they are not harmful, 
e.g. AI systems that might enable surveillance; persuasion/manipulation; 
or any which might be considered “human experimentation”. 
AI systems in these categories must follow specific guidance provided to staff 
by responsible domain leaders. As a matter of due diligence, 
AI systems should be evaluated by SIL creators and users to ensure they do not have 
disproportionate negative social, economic or environmental impact.

<b>Self-Determination for Local Language Communities</b>

While the development of AI tools has been global and anglocentric, 
for these technologies to serve local language communities, 
they must respond to the perceived and real needs of the local community itself. 
That is, the technology must be locally rooted in the needs of the community. 
To ensure this aim is met, we will strive to engage early in the process with affected communities. 
Community needs will inform development, and the ultimate determination 
of which technologies are deployed for the community will reside within the affected communities. 
Where AI tools are deployed for the benefit of local communities, 
local community representatives will be respected as stakeholders.

<b>Contact</b>

For questions or comments regarding any of the above guidance, [click here](https://forms.gle/6HoH2n52R7j2ewf46). 
To report a violation of this ethical statement, [click here](http://www.lighthouse-services.com/sil). 
NOTE: A violation should represent a serious concern; 
anything that you would not consider a serious concern should be shared as a question or comment.

<b>Consulted Sources</b>

- [UNESCO: Recommendation on the ethics of artificial intelligence](https://en.unesco.org/artificial-intelligence/ethics)
- [Artificial Intelligence at Google: Our Principles](https://ai.google/principles/)
- [Usage Guidelines for the OpenAI API](https://beta.openai.com/docs/usage-guidelines/usage-guidelines)
- [Microsoft Responsible AI Principles in Practice](https://www.microsoft.com/en-us/ai/responsible-ai)
- [Association for Computing Machinery Code of Ethics](https://www.acm.org/code-of-ethics)
- [Blueprint for an AI Bill of Rights](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)
- [EU General Data Protection Regulation](https://gdpr.eu/)
- [California Consumer Privacy Act of 2018](https://oag.ca.gov/privacy/ccpa)
- [Canadian Consumer Privacy Protection Act](https://ised-isde.canada.ca/site/innovation-better-canada/en/consumer-privacy-protection-act)
- [The UK Data Protection Act](https://www.gov.uk/data-protection)
- [New Zealand Privacy Act 2020](https://www.privacy.org.nz/privacy-act-2020/privacy-principles/)
- [UN Conference on Trade and Development, Data Protection and Privacy Legislation Worldwide](https://unctad.org/page/data-protection-and-privacy-legislation-worldwide)
- [SIL Mission and Values](https://www.sil.org/about)